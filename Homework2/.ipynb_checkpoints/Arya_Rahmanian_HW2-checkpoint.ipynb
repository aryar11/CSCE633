{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf503fa",
   "metadata": {},
   "source": [
    "# Homework 2 - CSCE 633\n",
    "## Arya Rahmanian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2ac8b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38c21a41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dd728",
   "metadata": {},
   "source": [
    "## Part A - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf28588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hitters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2530eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Player  AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  \\\n",
      "0     -Andy Allanson    293    66      1    30   29     14      1     293   \n",
      "1        -Alan Ashby    315    81      7    24   38     39     14    3449   \n",
      "2       -Alvin Davis    479   130     18    66   72     76      3    1624   \n",
      "3      -Andre Dawson    496   141     20    65   78     37     11    5628   \n",
      "4  -Andres Galarraga    321    87     10    39   42     30      2     396   \n",
      "\n",
      "   CHits  ...  CRuns  CRBI  CWalks  League Division PutOuts  Assists  Errors  \\\n",
      "0     66  ...     30    29      14       A        E     446       33      20   \n",
      "1    835  ...    321   414     375       N        W     632       43      10   \n",
      "2    457  ...    224   266     263       A        W     880       82      14   \n",
      "3   1575  ...    828   838     354       N        E     200       11       3   \n",
      "4    101  ...     48    46      33       N        E     805       40       4   \n",
      "\n",
      "   Salary  NewLeague  \n",
      "0     NaN          A  \n",
      "1   475.0          N  \n",
      "2   480.0          A  \n",
      "3   500.0          N  \n",
      "4    91.5          N  \n",
      "\n",
      "[5 rows x 21 columns] \n",
      "\n",
      "The shape of the dataset before preprocessing is:  (322, 21)\n"
     ]
    }
   ],
   "source": [
    "print(df.head() , \"\\n\")\n",
    "print(\"The shape of the dataset before preprocessing is: \", df.shape)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607c190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels and features\n",
    "\n",
    "label = df[\"NewLeague\"]\n",
    "\n",
    "feature = df.drop(\"NewLeague\", axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45bf21",
   "metadata": {},
   "source": [
    "### One-hot encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ea320f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numbers\n",
    "\n",
    "numbers = feature.select_dtypes(include=['int64', 'float64'])\n",
    "# select everything else\n",
    "not_numbers = feature.select_dtypes(exclude=['int64', 'float64'])\n",
    "\n",
    "# get_dummies and concact\n",
    "features = pd.concat([numbers, pd.get_dummies(not_numbers)],axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bf8bd",
   "metadata": {},
   "source": [
    "### Transform labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c24bbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.replace('A', 0, inplace=True)\n",
    "label.replace('N', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156cc233",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8cef5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcc49a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5f2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.costs = []\n",
    "\n",
    "    def initialize_params(self, n_features):\n",
    "        self.W = np.zeros((n_features, 1))\n",
    "        self.b = 0\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        # Ensure z is a numpy array\n",
    "        z = np.array(z)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def propagate(self, X, Y):\n",
    "        m = X.shape[1]  # number of examples\n",
    "        \n",
    "        # Forward propagation\n",
    "        A = self.sigmoid(np.dot(self.W.T, X) + self.b)\n",
    "        cost = -1/m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "        \n",
    "        # Backward propagation\n",
    "        dW = 1/m * np.dot(X, (A - Y).T)\n",
    "        db = 1/m * np.sum(A - Y)\n",
    "        \n",
    "        return dW, db, cost\n",
    "\n",
    "    def optimize(self, X, Y):\n",
    "        for i in range(self.num_iterations):\n",
    "            dW, db, cost = self.propagate(X, Y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.W = self.W - self.learning_rate * dW\n",
    "            self.b = self.b - self.learning_rate * db\n",
    "            \n",
    "            # Record the costs\n",
    "            if i % 100 == 0:\n",
    "                self.costs.append(cost)\n",
    "                print(f\"Cost after iteration {i}: {cost}\")\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        n_features = X_train.shape[0]\n",
    "        self.initialize_params(n_features)\n",
    "        \n",
    "        self.optimize(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        m = X.shape[1]\n",
    "        Y_prediction = np.zeros((1, m))\n",
    "        A = self.sigmoid(np.dot(self.W.T, X) + self.b)\n",
    "        \n",
    "        for i in range(A.shape[1]):\n",
    "            Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "        \n",
    "        return Y_prediction\n",
    "    def evaluate(self, X_train, y_train, X_test, y_test):\n",
    "        Y_prediction_train = self.predict(X_train)\n",
    "        Y_prediction_test = self.predict(X_test)\n",
    "        \n",
    "        train_accuracy = 100 - np.mean(np.abs(Y_prediction_train - y_train)) * 100\n",
    "        test_accuracy = 100 - np.mean(np.abs(Y_prediction_test - y_test)) * 100\n",
    "        \n",
    "        print(f\"train accuracy: {train_accuracy} %\")\n",
    "        print(f\"test accuracy: {test_accuracy} %\")\n",
    "        \n",
    "        return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef4cc932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Building Logistic Regression Model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_np, y_train_np)\n\u001b[0;32m     10\u001b[0m train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_train_np, y_train_np, X_test_np, y_test_np)\n",
      "Cell \u001b[1;32mIn[33], line 49\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     46\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_params(n_features)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[33], line 34\u001b[0m, in \u001b[0;36mLogisticRegression.optimize\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations):\n\u001b[1;32m---> 34\u001b[0m         dW, db, cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(X, Y)\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m dW\n",
      "Cell \u001b[1;32mIn[33], line 23\u001b[0m, in \u001b[0;36mLogisticRegression.propagate\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     20\u001b[0m m \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# number of examples\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Forward propagation\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mT, X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m     24\u001b[0m cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(Y \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(A) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Y) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m A))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Backward propagation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m, in \u001b[0;36mLogisticRegression.sigmoid\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     15\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(z)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(z)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mz))\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable exp method"
     ]
    }
   ],
   "source": [
    "X_train_np = X_train.to_numpy().T\n",
    "X_test_np = X_test.to_numpy().T\n",
    "y_train_np = y_train.to_numpy().reshape(1, -1)\n",
    "y_test_np = y_test.to_numpy().reshape(1, -1)\n",
    "\n",
    "model = LogisticRegression(learning_rate=0.001, num_iterations=3000)\n",
    "\n",
    "#Building Logistic Regression Model\n",
    "model.fit(X_train_np, y_train_np)\n",
    "train_accuracy, test_accuracy = model.evaluate(X_train_np, y_train_np, X_test_np, y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b8c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
