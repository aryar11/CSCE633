{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a116e89e-6588-424a-b975-8690900716e8",
      "metadata": {
        "id": "a116e89e-6588-424a-b975-8690900716e8"
      },
      "source": [
        "# Final Project\n",
        "## CSCE 633\n",
        "## Arya Rahmanian\n",
        "## Summer 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6918d-63c6-4660-96b9-3b9aab2dfb6e",
      "metadata": {
        "id": "c0a6918d-63c6-4660-96b9-3b9aab2dfb6e"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'yelp_review_full/train-00000-of-00001.parquet', 'test': 'yelp_review_full/test-00000-of-00001.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/Yelp/yelp_review_full/\" + splits[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyjcJfIxUDwk",
        "outputId": "3f700c8c-5b07-4e83-cff4-50e6d52a0a7d"
      },
      "id": "MyjcJfIxUDwk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e07bff3-7c39-4dde-aa45-654cfd79f7d6",
      "metadata": {
        "id": "1e07bff3-7c39-4dde-aa45-654cfd79f7d6"
      },
      "outputs": [],
      "source": [
        "# get train and test df\n",
        "train_df = pd.read_parquet(\"hf://datasets/Yelp/yelp_review_full/\" + splits[\"train\"])\n",
        "test_df = pd.read_parquet(\"hf://datasets/Yelp/yelp_review_full/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly select data points and split data into train, test, and valid\n",
        "train_data = train_df.sample(n=10000, random_state=42)\n",
        "val_data = train_df.drop(train_data.index).sample(n=1000, random_state=42)\n",
        "test_data = test_df.sample(n=2000, random_state=42)\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpoV5ZXvUHsG",
        "outputId": "10ef593c-926f-440c-d591-78bb2d8da18f"
      },
      "id": "GpoV5ZXvUHsG",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "        label                                               text\n",
            "177288      0  First of all i'm not a big fan of buffet, i tr...\n",
            "238756      1  Thanks Yelp. I was looking for the words to de...\n",
            "604225      2  Service was so-so. They were receiving a deliv...\n",
            "2838        2  Stamoolis Brothers is one of the Strip Distric...\n",
            "586957      0  I want to give a 2 stars because the service s...\n",
            "\n",
            "Test Data:\n",
            "       label                                               text\n",
            "33553      4  Came a few days ago for a lease, wasn't sure o...\n",
            "9427       0  I chose the 4 Queens for my visit to Las Vegas...\n",
            "199        3  I went here on the day of a wedding (I'm from ...\n",
            "12447      1  Isn't it strange how the little things can sou...\n",
            "39489      4  Visit here several times a year. The food is a...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "def download_glove_file(url, save_path='glove.twitter.27B.200d.txt'):\n",
        "    response = requests.get(url)\n",
        "    with open(save_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    return save_path\n"
      ],
      "metadata": {
        "id": "mdZr67hQTe2V"
      },
      "id": "mdZr67hQTe2V",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_url = \"https://huggingface.co/spaces/grs2001/Helloglove/resolve/85085196f7dbe75aa83901aebbfc3b9c4ab4aae4/glove.twitter.27B.200d.txt\"\n",
        "\n",
        "# Download the GloVe embeddings\n",
        "glove_file = download_glove_file(glove_url)"
      ],
      "metadata": {
        "id": "wGiZXK23TiW7"
      },
      "id": "wGiZXK23TiW7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5d40a136-0129-44c9-bc6e-38c06e86d021",
      "metadata": {
        "id": "5d40a136-0129-44c9-bc6e-38c06e86d021"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embedding_dict = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype='float32')\n",
        "            embedding_dict[word] = vector\n",
        "    return embedding_dict\n",
        "\n",
        "\n",
        "glove_file = 'glove.twitter.27B.200d.txt'\n",
        "\n",
        "embedding_dict = load_glove_embeddings(glove_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f502c828-6b04-4f06-bcf4-dca94bd72064",
      "metadata": {
        "id": "f502c828-6b04-4f06-bcf4-dca94bd72064"
      },
      "source": [
        "### Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "94fa5e05-19ec-4351-9dea-964b0c7b638e",
      "metadata": {
        "id": "94fa5e05-19ec-4351-9dea-964b0c7b638e"
      },
      "outputs": [],
      "source": [
        "def map_labels(stars):\n",
        "    return 0 if stars < 3 else 1\n",
        "\n",
        "# create our label column\n",
        "train_data['label'] = train_data['label'].apply(map_labels)\n",
        "test_data['label'] = test_data['label'].apply(map_labels)\n",
        "val_data['label'] = val_data['label'].apply(map_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bb38ce9b-96ad-4420-ba9a-912fe2b8933a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb38ce9b-96ad-4420-ba9a-912fe2b8933a",
        "outputId": "385d048f-a146-4811-cf45-938572578b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stop words\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
        "val_data['text'] = val_data['text'].apply(preprocess_text)\n",
        "test_data['text'] = test_data['text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2057554c-7151-4d64-b2f8-552422456cc2",
      "metadata": {
        "id": "2057554c-7151-4d64-b2f8-552422456cc2"
      },
      "source": [
        "### Tokenize and Pad Text Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "5c716a79-71d4-43e4-8952-d9a417acbbad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c716a79-71d4-43e4-8952-d9a417acbbad",
        "outputId": "0ae29354-63d6-4953-e0c5-5267536c00d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 300)\n",
            "(1000, 300)\n",
            "(2000, 300)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "val_sequences = tokenizer.texts_to_sequences(val_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# max length for sequences\n",
        "max_length = 300\n",
        "\n",
        "pad_last_words = False\n",
        "if(pad_last_words):\n",
        "    # Pad the last n characters\n",
        "    train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='pre')\n",
        "    val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post', truncating='pre')\n",
        "    test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='pre')\n",
        "else:\n",
        "    # Pad the first n characters\n",
        "    train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# shape of padded sequences\n",
        "print(train_padded.shape)\n",
        "print(val_padded.shape)\n",
        "print(test_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "4776748d-1cb6-487a-9f06-3c2cd3557f8b",
      "metadata": {
        "id": "4776748d-1cb6-487a-9f06-3c2cd3557f8b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Create embedding matrix\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embed_dim = 200  # GloVe dimension\n",
        "embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index >= vocab_size:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "\n",
        "# Convert embedding matrix to tensor\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc2e052-e3b8-4f68-8fd5-162cc79b81bc",
      "metadata": {
        "id": "2cc2e052-e3b8-4f68-8fd5-162cc79b81bc"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da5e984-c66d-4c35-a4e3-2ce86d57fe85",
      "metadata": {
        "id": "6da5e984-c66d-4c35-a4e3-2ce86d57fe85"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "f6e63601-75be-425f-b4fa-2df85cd14d29",
      "metadata": {
        "id": "f6e63601-75be-425f-b4fa-2df85cd14d29"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TransformerSentimentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_length, embedding_matrix):\n",
        "        super(TransformerSentimentClassifier, self).__init__()\n",
        "\n",
        "        # embedding layer\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "\n",
        "        # positional encoding\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, max_length, embed_dim))\n",
        "\n",
        "        # transformer encoder layers\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "\n",
        "        #self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch_size, max_length, embed_dim)\n",
        "        x += self.positional_encoding[:, :x.size(1), :]\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.transformer_encoder(x)  # (max_length, batch_size, embed_dim)\n",
        "\n",
        "        x = x.mean(dim=0)  # (batch_size, embed_dim)\n",
        "        x = self.fc(x)  # (batch_size, num_classes)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641b99d6-d0b5-4ccd-b423-cbfd3f495425",
      "metadata": {
        "id": "641b99d6-d0b5-4ccd-b423-cbfd3f495425"
      },
      "source": [
        "#### Hyper-params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5771c2ad-8dd6-42c1-a263-ce8cec6c665a",
      "metadata": {
        "id": "5771c2ad-8dd6-42c1-a263-ce8cec6c665a"
      },
      "source": [
        "#### Build Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "fafb413e-8f91-435c-90ed-c8abb2d8bee4",
      "metadata": {
        "id": "fafb413e-8f91-435c-90ed-c8abb2d8bee4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# convert to Torch tensors\n",
        "X_train = torch.tensor(train_padded, dtype=torch.long)\n",
        "y_train = torch.tensor(train_data['label'].values, dtype=torch.long)\n",
        "X_val = torch.tensor(val_padded, dtype=torch.long)\n",
        "y_val = torch.tensor(val_data['label'].values, dtype=torch.long)\n",
        "X_test = torch.tensor(test_padded, dtype=torch.long)\n",
        "y_test = torch.tensor(test_data['label'].values, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "008b5a21-e1cf-417b-aace-a7ae185c06d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "008b5a21-e1cf-417b-aace-a7ae185c06d7",
        "outputId": "0e00866a-83c8-46d5-e0ea-3d6f9a7a4206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerSentimentClassifier(\n",
            "  (embedding): Embedding(46883, 200)\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-11): 12 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=200, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=512, out_features=200, bias=True)\n",
            "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "embed_dim = 200\n",
        "num_heads = 20\n",
        "hidden_dim = 512\n",
        "num_layers = 12\n",
        "num_classes = 2\n",
        "\n",
        "# Initialize the model\n",
        "model = TransformerSentimentClassifier(vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_length, embedding_matrix)\n",
        "\n",
        "# Display the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adc0f83f-7802-4507-8606-bb4f8cf0a876",
      "metadata": {
        "id": "adc0f83f-7802-4507-8606-bb4f8cf0a876"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "3aecbc3f-095d-473c-ab84-d24ade9d3e83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aecbc3f-095d-473c-ab84-d24ade9d3e83",
        "outputId": "30328355-5617-4abb-b5ce-c44a5252a6af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerSentimentClassifier(\n",
              "  (embedding): Embedding(46883, 200)\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=200, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=200, bias=True)\n",
              "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW, Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# lists to store training metrics\n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies, val_accuracies = [], []\n",
        "\n",
        "# constants hyper params\n",
        "EPOCHS = 6\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "# init optimizer, and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf93226e-e9c2-463e-ac33-0f39aebdcf2e",
      "metadata": {
        "id": "cf93226e-e9c2-463e-ac33-0f39aebdcf2e"
      },
      "source": [
        "#### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0dc5910-f18f-458a-b927-fd684ea313b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0dc5910-f18f-458a-b927-fd684ea313b1",
        "outputId": "3e50eaf9-35e4-4ddc-d113-08455b86e9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6, Loss: 0.5271, Accuracy: 0.7323\n",
            "Validation Loss: 0.4485, Validation Accuracy: 0.7930\n",
            "Epoch 2/6, Loss: 0.4220, Accuracy: 0.8002\n",
            "Validation Loss: 0.4069, Validation Accuracy: 0.8090\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_predictions += (preds == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_predictions += (preds == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20ad4e58-6104-4326-b29b-cef2e2eec0ba",
      "metadata": {
        "id": "20ad4e58-6104-4326-b29b-cef2e2eec0ba"
      },
      "source": [
        "### Plot Training Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12a0f00d-0e01-45b1-9b0d-723b40727416",
      "metadata": {
        "id": "12a0f00d-0e01-45b1-9b0d-723b40727416"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, EPOCHS + 1)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4cde94b-a15c-428a-8c0c-00a3c6fce256",
      "metadata": {
        "id": "c4cde94b-a15c-428a-8c0c-00a3c6fce256"
      },
      "source": [
        "### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cacb9a1-46be-4855-883b-66cc94d2dca2",
      "metadata": {
        "id": "7cacb9a1-46be-4855-883b-66cc94d2dca2"
      },
      "outputs": [],
      "source": [
        "model_save_path = 'yelp_classifer_model.pth'\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b2303c-9fbd-4197-8f87-1db0e68034e2",
      "metadata": {
        "id": "47b2303c-9fbd-4197-8f87-1db0e68034e2"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8dda985-2f7c-4de1-ba73-bfe2e8cdd0cc",
      "metadata": {
        "id": "b8dda985-2f7c-4de1-ba73-bfe2e8cdd0cc"
      },
      "source": [
        "#### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfabea3-d413-4eab-b42c-34da9d93d418",
      "metadata": {
        "id": "abfabea3-d413-4eab-b42c-34da9d93d418",
        "outputId": "ae6e3af1-f9f5-4ac1-d2b6-0d38786c237b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Airsight\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TransformerSentimentClassifier(\n",
              "  (embedding): Embedding(30165, 200)\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=200, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=200, bias=True)\n",
              "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 281,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model = TransformerSentimentClassifier(vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_length, embedding_matrix)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "loaded_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c3dd04-d4eb-404a-b899-b2feb7f020b4",
      "metadata": {
        "id": "57c3dd04-d4eb-404a-b899-b2feb7f020b4"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "0e58eb5a-2e1f-44db-8543-152952cfc333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e58eb5a-2e1f-44db-8543-152952cfc333",
        "outputId": "808498c6-b1b1-4590-c9d4-f4be2ddb526b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5293\n",
            "Test Accuracy: 81.35%\n",
            "Precision: 0.81\n",
            "Recall: 0.71\n",
            "F1 Score: 0.76\n",
            "Confusion Matrix:\n",
            "[[1043  137]\n",
            " [ 236  584]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# evaluate model\n",
        "model.eval()\n",
        "\n",
        "# track loss and accuracy\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# lists to store true and predicted labels for metric calculation\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "# test\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_predictions += (preds == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "        # store true and predicted labels\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# calc average test loss and accuracy\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "# calculate additional metrics\n",
        "precision = precision_score(all_labels, all_preds, average='binary')\n",
        "recall = recall_score(all_labels, all_preds, average='binary')\n",
        "f1 = f1_score(all_labels, all_preds, average='binary')\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}